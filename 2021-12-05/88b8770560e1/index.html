<!doctype html><html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="baidu-site-verification" content="code-P4sIUGW5wS"><title>kubeadm安装kubernetes集群 - XuKun&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="XuKun&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="XuKun&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1. 安装说明虽然K8s 1.20版本宣布将在1.23版本之后将不再维护dockershim，意味着K8s将不直接支持Docker，不过大家不必过于担心。一是在1.23版本之前我们仍然可以使用Docker，二是dockershim肯定会有人接盘，我们同样可以使用Docker，三是Docker制作的镜像仍然可以在其他Runtime环境中使用，所以大家不必过于恐慌。 本次安装采用的是Kubeadm安装"><meta property="og:type" content="blog"><meta property="og:title" content="kubeadm安装kubernetes集群"><meta property="og:url" content="https://xukun0904.github.io/2021-12-05/88b8770560e1/"><meta property="og:site_name" content="XuKun&#039;s Blog"><meta property="og:description" content="1. 安装说明虽然K8s 1.20版本宣布将在1.23版本之后将不再维护dockershim，意味着K8s将不直接支持Docker，不过大家不必过于担心。一是在1.23版本之前我们仍然可以使用Docker，二是dockershim肯定会有人接盘，我们同样可以使用Docker，三是Docker制作的镜像仍然可以在其他Runtime环境中使用，所以大家不必过于恐慌。 本次安装采用的是Kubeadm安装"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://xukun0904.github.io/kubeadm%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4/20201212130124372.png"><meta property="og:image" content="file://D:/Resource/xukun_blog/source/_posts/2021/12/Kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/image-20211205133622828.png?lastModify=1638682375"><meta property="og:image" content="file://D:/Resource/xukun_blog/source/_posts/2021/12/Kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/image-20211205133743076.png?lastModify=1638682375"><meta property="article:published_time" content="2021-12-05T05:57:46.000Z"><meta property="article:modified_time" content="2021-12-05T06:02:24.601Z"><meta property="article:author" content="蔚蓝海"><meta property="article:tag" content="Kubernetes"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/kubeadm%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4/20201212130124372.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xukun0904.github.io/2021-12-05/88b8770560e1/"},"headline":"kubeadm安装kubernetes集群","image":["https://xukun0904.github.io/kubeadm%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4/20201212130124372.png"],"datePublished":"2021-12-05T05:57:46.000Z","dateModified":"2021-12-05T06:02:24.601Z","author":{"@type":"Person","name":"蔚蓝海"},"publisher":{"@type":"Organization","name":"XuKun's Blog","logo":{"@type":"ImageObject","url":null}},"description":"1. 安装说明虽然K8s 1.20版本宣布将在1.23版本之后将不再维护dockershim，意味着K8s将不直接支持Docker，不过大家不必过于担心。一是在1.23版本之前我们仍然可以使用Docker，二是dockershim肯定会有人接盘，我们同样可以使用Docker，三是Docker制作的镜像仍然可以在其他Runtime环境中使用，所以大家不必过于恐慌。 本次安装采用的是Kubeadm安装"}</script><link rel="canonical" href="https://xukun0904.github.io/2021-12-05/88b8770560e1/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-102687131-2" async></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-102687131-2")</script><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">XuKun&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-12-05T05:57:46.000Z" title="2021/12/5 下午1:57:46">2021-12-05</time>发表</span><span class="level-item"><time datetime="2021-12-05T06:02:24.601Z" title="2021/12/5 下午2:02:24">2021-12-05</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/">工具安装</a><span> / </span><a class="link-muted" href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/%E5%90%8E%E7%AB%AF/">后端</a></span><span class="level-item">26 分钟读完 (大约3953个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">kubeadm安装kubernetes集群</h1><div class="content"><h2 id="1-安装说明"><a href="#1-安装说明" class="headerlink" title="1. 安装说明"></a>1. 安装说明</h2><p>虽然K8s 1.20版本宣布将在1.23版本之后将不再维护dockershim，意味着K8s将不直接支持Docker，不过大家不必过于担心。一是在1.23版本之前我们仍然可以使用Docker，二是dockershim肯定会有人接盘，我们同样可以使用Docker，三是Docker制作的镜像仍然可以在其他Runtime环境中使用，所以大家不必过于恐慌。</p><p>本次安装采用的是Kubeadm安装工具，安装版本是K8s 1.22+，采用的系统为CentOS 7.9，其中Master节点3台，Node节点2台，高可用工具采用HAProxy + KeepAlived。</p><h2 id="2-节点规划"><a href="#2-节点规划" class="headerlink" title="2. 节点规划"></a>2. 节点规划</h2><table><thead><tr><th align="center">主机名</th><th align="center">IP地址</th><th align="center">角色</th><th align="center">配置</th></tr></thead><tbody><tr><td align="center">k8s-master01 ~ 03</td><td align="center">192.168.1.201 ~ 203</td><td align="center">Master/Worker节点</td><td align="center">2C2G 40G</td></tr><tr><td align="center">k8s-node01 ~ 02</td><td align="center">192.168.1.204 ~ 205</td><td align="center">Worker节点</td><td align="center">2C2G 40G</td></tr><tr><td align="center">k8s-master-lb</td><td align="center">192.168.1.236</td><td align="center">VIP</td><td align="center">VIP不占用机器</td></tr></tbody></table><table><thead><tr><th align="center">信息</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">系统版本</td><td align="center">CentOS 7.9</td></tr><tr><td align="center">Docker版本</td><td align="center">19.03.x</td></tr><tr><td align="center">K8s版本</td><td align="center">1.20.x</td></tr><tr><td align="center">Pod网段</td><td align="center">172.168.0.0/16</td></tr><tr><td align="center">Service网段</td><td align="center">10.96.0.0/12</td></tr></tbody></table><h2 id="3-基本配置"><a href="#3-基本配置" class="headerlink" title="3. 基本配置"></a>3. 基本配置</h2><p>静态IP配置，hostname设置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"></span><br><span class="line">BOOTPROTO=&quot;static&quot;</span><br><span class="line">IPADDR=192.168.1.201</span><br><span class="line">GATEWAY=192.168.1.1</span><br><span class="line">DNS1=192.168.1.1</span><br><span class="line"></span><br><span class="line">service network restart</span><br><span class="line"></span><br><span class="line">hostname k8s-master01</span><br><span class="line">vi /etc/hostname</span><br><span class="line">k8s-master01</span><br></pre></td></tr></table></figure><p>所有节点配置hosts</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# cat /etc/hosts</span><br><span class="line">192.168.1.201 k8s-master01</span><br><span class="line">192.168.1.202 k8s-master02</span><br><span class="line">192.168.1.203 k8s-master03</span><br><span class="line">192.168.1.236 k8s-master-lb # 如果不是高可用集群，该IP为Master01的IP</span><br><span class="line">192.168.1.204 k8s-node01</span><br><span class="line">192.168.1.205 k8s-node02</span><br></pre></td></tr></table></figure><p>yum源配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line">sed -i -e &#x27;/mirrors.cloud.aliyuncs.com/d&#x27; -e &#x27;/mirrors.aliyuncs.com/d&#x27; /etc/yum.repos.d/CentOS-Base.repo</span><br></pre></td></tr></table></figure><p>必备工具安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y</span><br></pre></td></tr></table></figure><p>所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable --now firewalld </span><br><span class="line">systemctl disable --now dnsmasq</span><br><span class="line">systemctl disable --now NetworkManager</span><br><span class="line"></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/sysconfig/selinux</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure><p>关闭swap分区</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">sed -ri &#x27;/^[^#]*swap/s@^@#@&#x27; /etc/fstab</span><br></pre></td></tr></table></figure><p>安装ntpdate</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm</span><br><span class="line">yum install ntpdate -y</span><br></pre></td></tr></table></figure><p>所有节点同步时间。时间同步配置如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezone</span><br><span class="line">ntpdate time2.aliyun.com</span><br></pre></td></tr></table></figure><p>加入到crontab</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br><span class="line">*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com</span><br></pre></td></tr></table></figure><p>所有节点配置limit：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line"></span><br><span class="line">vim /etc/security/limits.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 末尾添加如下内容</span></span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* soft memlock unlimited</span><br><span class="line">* hard memlock unlimited</span><br></pre></td></tr></table></figure><p>Master01节点免密钥登录其他节点：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line"></span><br><span class="line">for i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done</span><br></pre></td></tr></table></figure><p>下载安装所有的源码文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/</span><br><span class="line">git clone https://github.com/xukun0904/k8s-ha-install.git</span><br></pre></td></tr></table></figure><p>所有节点升级系统并重启：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update -y  &amp;&amp; reboot</span><br></pre></td></tr></table></figure><h2 id="4-内核配置"><a href="#4-内核配置" class="headerlink" title="4. 内核配置"></a>4. 内核配置</h2><p>所有节点内核升级</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-5.14.3-1.el7.elrepo.x86_64.rpm</span><br><span class="line">wget https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-ml-devel-5.14.3-1.el7.elrepo.x86_64.rpm</span><br><span class="line">yum -y install kernel-ml-5.14.3-1.el7.elrepo.x86_64.rpm kernel-ml-devel-5.14.3-1.el7.elrepo.x86_64.rpm</span><br><span class="line">cat /boot/grub2/grub.cfg |grep menuentry</span><br><span class="line">grub2-set-default &quot;CentOS Linux (5.14.3-1.el7.elrepo.x86_64) 7 (Core)&quot;</span><br><span class="line">grub2-editenv list</span><br></pre></td></tr></table></figure><p>所有节点安装ipvsadm：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br></pre></td></tr></table></figure><p>所有节点配置ipvs模块，4.19以下内核<strong>nf_conntrack_ipv4</strong> 4.19以上内核为<strong>nf_conntrack</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/modules-load.d/ipvs.conf </span><br><span class="line"><span class="meta">#</span><span class="bash"> 加入以下内容</span></span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_lc</span><br><span class="line">ip_vs_wlc</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_lblc</span><br><span class="line">ip_vs_lblcr</span><br><span class="line">ip_vs_dh</span><br><span class="line">ip_vs_sh</span><br><span class="line">ip_vs_fo</span><br><span class="line">ip_vs_nq</span><br><span class="line">ip_vs_sed</span><br><span class="line">ip_vs_ftp</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br></pre></td></tr></table></figure><p>加载内核配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable --now systemd-modules-load.service</span><br></pre></td></tr></table></figure><p>开启一些k8s集群中必须的内核参数，所有节点配置k8s内核</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br><span class="line">reboot</span><br><span class="line">lsmod|grep -e ip_vs -e nf_conntrack</span><br></pre></td></tr></table></figure><h2 id="5-基本组件安装"><a href="#5-基本组件安装" class="headerlink" title="5. 基本组件安装"></a>5. 基本组件安装</h2><p>所有节点安装Docker-ce 19.03</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-ce-19.03.* -y</span><br></pre></td></tr></table></figure><p>所有节点设置开机自启动Docker</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now docker</span><br></pre></td></tr></table></figure><p>安装k8s组件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum list kubeadm.x86_64 --showduplicates | sort -r</span><br></pre></td></tr></table></figure><p>所有节点安装最新版本kubeadm</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install kubeadm -y</span><br></pre></td></tr></table></figure><p>默认配置的pause镜像使用gcr.io仓库，国内可能无法访问，所以这里配置Kubelet使用阿里云的pause镜像：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/sysconfig/kubelet&lt;&lt;EOF</span><br><span class="line">KUBELET_EXTRA_ARGS=&quot;--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.2&quot;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 新版kubelet建议使用systemd，所以可以把cgroupdriver改为systemd</span></span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><p>设置Kubelet开机自启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure><h2 id="6-高可用组件安装"><a href="#6-高可用组件安装" class="headerlink" title="6. 高可用组件安装"></a>6. 高可用组件安装</h2><p><strong>注意：如果不是高可用集群或者在云上安装，haproxy和keepalived无需安装</strong><br><strong>所有Master节点</strong>通过yum安装HAProxy和KeepAlived：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install keepalived haproxy -y</span><br></pre></td></tr></table></figure><p><strong>所有Master节点</strong>配置HAProxy（详细配置参考HAProxy文档，所有Master节点的HAProxy配置相同）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 etc]# mkdir /etc/haproxy</span><br><span class="line">[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg </span><br><span class="line">global</span><br><span class="line">  maxconn  2000</span><br><span class="line">  ulimit-n  16384</span><br><span class="line">  log  127.0.0.1 local0 err</span><br><span class="line">  stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  log global</span><br><span class="line">  mode  http</span><br><span class="line">  option  httplog</span><br><span class="line">  timeout connect 5000</span><br><span class="line">  timeout client  50000</span><br><span class="line">  timeout server  50000</span><br><span class="line">  timeout http-request 15s</span><br><span class="line">  timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line">  bind *:33305</span><br><span class="line">  mode http</span><br><span class="line">  option httplog</span><br><span class="line">  monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line">  bind 0.0.0.0:16443</span><br><span class="line">  bind 127.0.0.1:16443</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  tcp-request inspect-delay 5s</span><br><span class="line">  default_backend k8s-master</span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  option tcp-check</span><br><span class="line">  balance roundrobin</span><br><span class="line">  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">  server k8s-master01	192.168.1.201:6443  check</span><br><span class="line">  server k8s-master02	192.168.1.202:6443  check</span><br><span class="line">  server k8s-master03	192.168.1.203:6443  check</span><br></pre></td></tr></table></figure><p>所有Master节点配置KeepAlived，配置不一样，注意区分<br>注意每个节点的IP和网卡（interface参数）<br>Master01节点的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 etc]# mkdir /etc/keepalived</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf </span><br><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">script_user root</span><br><span class="line">    enable_script_security</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5</span><br><span class="line">    weight -5</span><br><span class="line">    fall 2  </span><br><span class="line">rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    mcast_src_ip 192.168.1.201</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 101</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.236</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">       chk_apiserver</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Master02节点的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">script_user root</span><br><span class="line">    enable_script_security</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">   interval 5</span><br><span class="line">    weight -5</span><br><span class="line">    fall 2  </span><br><span class="line">rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens33</span><br><span class="line">    mcast_src_ip 192.168.1.202</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.236</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">       chk_apiserver</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Master03节点的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">script_user root</span><br><span class="line">    enable_script_security</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line"> interval 5</span><br><span class="line">    weight -5</span><br><span class="line">    fall 2  </span><br><span class="line">rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens33</span><br><span class="line">    mcast_src_ip 192.168.1.203</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.236</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">       chk_apiserver</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为<strong>所有master节点</strong>配置KeepAlived健康检查文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh </span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in $(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=$(pgrep haproxy)</span><br><span class="line">    if [[ $check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=$(expr $err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ $err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">scp /etc/keepalived/check_apiserver.sh k8s-master02:/etc/keepalived/</span><br><span class="line"></span><br><span class="line">scp /etc/keepalived/check_apiserver.sh k8s-master03:/etc/keepalived/</span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">启动haproxy和keepalived</span></span><br><span class="line">[root@k8s-master01 keepalived]# systemctl daemon-reload</span><br><span class="line">[root@k8s-master01 keepalived]# systemctl enable --now haproxy</span><br><span class="line">[root@k8s-master01 keepalived]# systemctl enable --now keepalived</span><br></pre></td></tr></table></figure><p>测试VIP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# ping 192.168.1.236 -c 4</span><br><span class="line">PING 192.168.1.236 (192.168.1.236) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.1.236: icmp_seq=1 ttl=64 time=0.464 ms</span><br><span class="line">64 bytes from 192.168.1.236: icmp_seq=2 ttl=64 time=0.063 ms</span><br><span class="line">64 bytes from 192.168.1.236: icmp_seq=3 ttl=64 time=0.062 ms</span><br><span class="line">64 bytes from 192.168.1.236: icmp_seq=4 ttl=64 time=0.063 ms</span><br></pre></td></tr></table></figure><h2 id="7-集群初始化"><a href="#7-集群初始化" class="headerlink" title="7. 集群初始化"></a>7. 集群初始化</h2><p><strong>Master01节点</strong>创建new.yaml配置文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">vim /root/new.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: 7t2weq.bjbawausm0jaxury</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 192.168.1.201</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  name: k8s-master01</span><br><span class="line">  taints:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  certSANs:</span><br><span class="line">  - 192.168.1.236</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controlPlaneEndpoint: 192.168.1.236:16443</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns:</span><br><span class="line">  type: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.20.0</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  podSubnet: 172.168.0.0/16</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure><p><strong>注意：如果不是高可用集群，192.168.1.236:16443改为master01的地址，16443改为apiserver的端口，默认是6443，注意更改v1.20.0为自己服务器kubeadm的版本：kubeadm version</strong><br>将new.yaml文件复制到<strong>其他master</strong>节点，之后<strong>所有Master节点</strong>提前下载镜像，可以节省初始化时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scp /root/new.yaml k8s-master02:/root/</span><br><span class="line"></span><br><span class="line">scp /root/new.yaml k8s-master03:/root/</span><br><span class="line"></span><br><span class="line">docker pull coredns/coredns:1.8.4</span><br><span class="line">docker tag coredns/coredns:1.8.4 registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4</span><br><span class="line">docker rmi coredns/coredns:1.8.4</span><br><span class="line"></span><br><span class="line">kubeadm config images pull --config /root/new.yaml </span><br></pre></td></tr></table></figure><p>所有节点设置开机自启动kubelet（如果启动失败无需管理，初始化成功以后即可启动）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure><p><strong>Master01节点初始化</strong>，初始化以后会在/etc/kubernetes目录下生成对应的证书和配置文件，之后其他Master节点加入Master01即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config /root/new.yaml  --upload-certs</span><br></pre></td></tr></table></figure><p>初始化成功以后，会产生Token值，用于其他节点加入时使用，因此要记录下初始化成功生成的token值（令牌值）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.1.236:16443 --token 7t2weq.bjbawausm0jaxury \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:5d5110b03c314d9dda442d6ff25ec251249edf017c5d2ef8f27831bde7a24933 \</span><br><span class="line">	--control-plane --certificate-key 9f98627d614bef2e9d51e2f064ef388a7b764aa7dd25a1dcccae86234e2c8cbf</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class="line">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.1.236:16443 --token 7t2weq.bjbawausm0jaxury \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:5d5110b03c314d9dda442d6ff25ec251249edf017c5d2ef8f27831bde7a24933</span><br></pre></td></tr></table></figure><p><strong>Master01节点</strong>配置环境变量，用于访问Kubernetes集群：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;&gt; /root/.bashrc</span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">EOF</span><br><span class="line">source /root/.bashrc</span><br></pre></td></tr></table></figure><p>查看节点状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> [root@k8s-master01 ~]# kubectl get nodes</span><br><span class="line">NAME           STATUS     ROLES                  AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   control-plane,master   74s   v1.20.0</span><br></pre></td></tr></table></figure><p>采用初始化安装方式，所有的系统组件均以容器的方式运行并且在kube-system命名空间内，此时可以查看Pod状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get pods -n kube-system -o wide</span><br><span class="line">NAME                                   READY     STATUS    RESTARTS   AGE       IP              NODE</span><br><span class="line">coredns-777d78ff6f-kstsz               0/1       Pending   0          14m       &lt;none&gt;          &lt;none&gt;</span><br><span class="line">coredns-777d78ff6f-rlfr5               0/1       Pending   0          14m       &lt;none&gt;          &lt;none&gt;</span><br><span class="line">etcd-k8s-master01                      1/1       Running   0          14m       192.168.1.201   k8s-master01</span><br><span class="line">kube-apiserver-k8s-master01            1/1       Running   0          13m       192.168.1.201   k8s-master01</span><br><span class="line">kube-controller-manager-k8s-master01   1/1       Running   0          13m       192.168.1.201   k8s-master01</span><br><span class="line">kube-proxy-8d4qc                       1/1       Running   0          14m       192.168.1.201   k8s-master01</span><br><span class="line">kube-scheduler-k8s-master01            1/1       Running   0          13m       192.168.1.201   k8s-master01</span><br></pre></td></tr></table></figure><h2 id="8-高可用Master"><a href="#8-高可用Master" class="headerlink" title="8. 高可用Master"></a>8. 高可用Master</h2><p>初始化其他master加入集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.1.236:16443 --token 7t2weq.bjbawausm0jaxury \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:5d5110b03c314d9dda442d6ff25ec251249edf017c5d2ef8f27831bde7a24933 \</span><br><span class="line">	--control-plane --certificate-key 9f98627d614bef2e9d51e2f064ef388a7b764aa7dd25a1dcccae86234e2c8cbf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">如果初始化失败，重置后再次初始化，命令如下：</span></span><br><span class="line">kubeadm reset -f</span><br><span class="line">ipvsadm --clear</span><br><span class="line">rm -rf ~/.kube</span><br></pre></td></tr></table></figure><p>Token过期处理方式</p><p>token会再两个小时后失效，生成新的token</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><p>Master需要生成–certificate-key</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init phase upload-certs --upload-certs</span><br><span class="line">kubectl get secret -n kube-system</span><br><span class="line">kubectl get secret -n kube-system bootstrap-token-7t2weq -oyaml</span><br></pre></td></tr></table></figure><p>使用新生成的token加入集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.1.236:16443 --token 7t2weq.bjbawausm0jaxury \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:5d5110b03c314d9dda442d6ff25ec251249edf017c5d2ef8f27831bde7a24933 \</span><br><span class="line">	--control-plane --certificate-key 9f98627d614bef2e9d51e2f064ef388a7b764aa7dd25a1dcccae86234e2c8cbf</span><br></pre></td></tr></table></figure><h2 id="9-添加Node节点"><a href="#9-添加Node节点" class="headerlink" title="9. 添加Node节点"></a>9. 添加Node节点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.1.236:16443 --token 7t2weq.bjbawausm0jaxury \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:5d5110b03c314d9dda442d6ff25ec251249edf017c5d2ef8f27831bde7a24933</span><br></pre></td></tr></table></figure><p>查看集群状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[root@k8s-master01]#</span><span class="bash"> kubectl  get node</span></span><br><span class="line">NAME           STATUS     ROLES                  AGE     VERSION</span><br><span class="line">k8s-master01   NotReady   control-plane,master   8m53s   v1.20.0</span><br><span class="line">k8s-master02   NotReady   control-plane,master   2m25s   v1.20.0</span><br><span class="line">k8s-master03   NotReady   control-plane,master   31s     v1.20.0</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;                 32s     v1.20.0</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;                 88s     v1.20.0</span><br></pre></td></tr></table></figure><h2 id="10-Calico安装"><a href="#10-Calico安装" class="headerlink" title="10. Calico安装"></a>10. Calico安装</h2><p>以下步骤<strong>只在master01</strong>执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/k8s-ha-install &amp;&amp; git checkout manual-installation-v1.21.x &amp;&amp; cd calico/</span><br></pre></td></tr></table></figure><p>修改calico-etcd.yaml的以下位置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s#etcd_endpoints: &quot;http://&lt;ETCD_IP&gt;:&lt;ETCD_PORT&gt;&quot;#etcd_endpoints: &quot;https://192.168.1.201:2379,https://192.168.1.202:2379,https://192.168.1.203:2379&quot;#g&#x27; calico-etcd.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ETCD_CA=`cat /etc/kubernetes/pki/etcd/ca.crt | base64 | tr -d &#x27;\n&#x27;`</span><br><span class="line">ETCD_CERT=`cat /etc/kubernetes/pki/etcd/server.crt | base64 | tr -d &#x27;\n&#x27;`</span><br><span class="line">ETCD_KEY=`cat /etc/kubernetes/pki/etcd/server.key | base64 | tr -d &#x27;\n&#x27;`</span><br><span class="line">sed -i &quot;s@# etcd-key: null@etcd-key: $&#123;ETCD_KEY&#125;@g; s@# etcd-cert: null@etcd-cert: $&#123;ETCD_CERT&#125;@g; s@# etcd-ca: null@etcd-ca: $&#123;ETCD_CA&#125;@g&quot; calico-etcd.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sed -i &#x27;s#etcd_ca: &quot;&quot;#etcd_ca: &quot;/calico-secrets/etcd-ca&quot;#g; s#etcd_cert: &quot;&quot;#etcd_cert: &quot;/calico-secrets/etcd-cert&quot;#g; s#etcd_key: &quot;&quot; #etcd_key: &quot;/calico-secrets/etcd-key&quot; #g&#x27; calico-etcd.yaml</span><br><span class="line"></span><br><span class="line">POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= &#x27;&#123;print $NF&#125;&#x27;`</span><br><span class="line"></span><br><span class="line">sed -i &#x27;s@# - name: CALICO_IPV4POOL_CIDR@- name: CALICO_IPV4POOL_CIDR@g; s@#   value: &quot;192.168.0.0/16&quot;@  value: &#x27;&quot;$&#123;POD_SUBNET&#125;&quot;&#x27;@g&#x27; calico-etcd.yaml</span><br></pre></td></tr></table></figure><p>创建calico</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f calico-etcd.yaml</span><br><span class="line"></span><br><span class="line">kubectl  get node</span><br><span class="line"></span><br><span class="line">kubectl get pods -n kube-system -o wide</span><br></pre></td></tr></table></figure><h2 id="11-Metrics-Server部署"><a href="#11-Metrics-Server部署" class="headerlink" title="11. Metrics Server部署"></a>11. Metrics Server部署</h2><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率。<br>将Master01节点的front-proxy-ca.crt复制到所有Node节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node01:/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class="line">scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node(其他节点自行拷贝):/etc/kubernetes/pki/front-proxy-ca.crt</span><br></pre></td></tr></table></figure><p>安装metrics server</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cd /root/k8s-ha-install/metrics-server-0.4.x-kubeadm/</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 metrics-server-0.4.x-kubeadm]# kubectl  create -f comp.yaml </span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br></pre></td></tr></table></figure><p>等待kube-system命令空间下的Pod全部启动后，查看状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n kube-system -o wide</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 metrics-server-0.4.x-kubeadm]# kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   109m         2%     1296Mi          33%       </span><br><span class="line">k8s-master02   99m          2%     1124Mi          29%       </span><br><span class="line">k8s-master03   104m         2%     1082Mi          28%       </span><br><span class="line">k8s-node01     55m          1%     761Mi           19%       </span><br><span class="line">k8s-node02     53m          1%     663Mi           17%</span><br><span class="line"></span><br><span class="line">kubectl top po -n kube-system</span><br><span class="line">NAME                                      CPU(cores)   MEMORY(bytes)   </span><br><span class="line">calico-kube-controllers-cdd5755b9-78fsd   3m           15Mi            </span><br><span class="line">calico-node-8m2wm                         35m          55Mi            </span><br><span class="line">calico-node-9cb4j                         39m          75Mi            </span><br><span class="line">calico-node-bljgv                         43m          77Mi            </span><br><span class="line">calico-node-chqv8                         39m          69Mi            </span><br><span class="line">calico-node-t97kd                         39m          80Mi            </span><br><span class="line">coredns-7d89d9b6b8-7zvlw                  2m           10Mi            </span><br><span class="line">coredns-7d89d9b6b8-zmth2                  2m           11Mi            </span><br><span class="line">etcd-k8s-master01                         54m          90Mi            </span><br><span class="line">etcd-k8s-master02                         44m          85Mi            </span><br><span class="line">etcd-k8s-master03                         39m          84Mi            </span><br><span class="line">kube-apiserver-k8s-master01               61m          311Mi           </span><br><span class="line">kube-apiserver-k8s-master02               53m          296Mi           </span><br><span class="line">kube-apiserver-k8s-master03               51m          283Mi           </span><br><span class="line">kube-controller-manager-k8s-master01      20m          53Mi            </span><br><span class="line">kube-controller-manager-k8s-master02      2m           27Mi            </span><br><span class="line">kube-controller-manager-k8s-master03      2m           24Mi            </span><br><span class="line">kube-proxy-fln4s                          1m           15Mi            </span><br><span class="line">kube-proxy-fnbns                          1m           12Mi            </span><br><span class="line">kube-proxy-hngtq                          1m           17Mi            </span><br><span class="line">kube-proxy-prk44                          1m           17Mi            </span><br><span class="line">kube-proxy-tn8bt                          1m           17Mi            </span><br><span class="line">kube-scheduler-k8s-master01               5m           22Mi            </span><br><span class="line">kube-scheduler-k8s-master02               3m           20Mi            </span><br><span class="line">kube-scheduler-k8s-master03               4m           19Mi            </span><br><span class="line">metrics-server-d6c46b546-5db6j            4m           26Mi</span><br></pre></td></tr></table></figure><h2 id="12-Dashboard部署"><a href="#12-Dashboard部署" class="headerlink" title="12. Dashboard部署"></a>12. Dashboard部署</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cd /root/k8s-ha-install/dashboard/</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 dashboard]# kubectl  create -f .</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br></pre></td></tr></table></figure><p>在谷歌浏览器（Chrome）启动文件中加入启动参数，用于解决无法访问Dashboard的问题，参考图：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--test-type --ignore-certificate-errors</span><br></pre></td></tr></table></figure><p>更改dashboard的svc为NodePort：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br></pre></td></tr></table></figure><p>将ClusterIP更改为NodePort（如果已经为NodePort忽略此步骤）：<br>查看端口号：<br><img src="/kubeadm%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4/20201212130124372.png" alt="在这里插入图片描述"><br>根据自己的实例端口号，通过任意安装了kube-proxy的宿主机或者VIP的IP+端口即可访问到dashboard：<br>访问Dashboard：<a target="_blank" rel="noopener" href="https://192.168.1.236:18282/">https://192.168.1.236:18282</a>（请更改18282为自己的端口），选择登录方式为令牌（即token方式）<br><img src="file://D:/Resource/xukun_blog/source/_posts/2021/12/Kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/image-20211205133622828.png?lastModify=1638682375" alt="image-20211205133622828"><br>查看token值：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 1.1.1]# kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">Name:         admin-user-token-7rp7r</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: 0839a328-b835-4c18-afff-651bf6f18c3f</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1099 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6Ilhma0NUMlRvVWM4S083OGMtd0U0T29DZXpwb2lzODZaa1hfTzdtZXU3LXcifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTdycDdyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwODM5YTMyOC1iODM1LTRjMTgtYWZmZi02NTFiZjZmMThjM2YiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.l3GdVKFrfZVrELYKtyR9h7bO-HWimYE8O9ZB2XX14GWifsfqvR4_nEHNLph4lZGoLJaNqHX1FR1An7PxDg-miRWIbl5Ms224D0ak4BtpyQUIWcdixNB5xkKJuLOypOiSa1beMYIpcpxQEj_zf3VUTmUFu7bb1EWnwkYXN9leuVoUREEq-Slw--KLA7l6V-3b8H4_mWU5LYaLYxq3G7Svvhn_N7lsn78J0oA4B_ViIjFlGB9TjxcnlTtI8CGPlSb54sJAPDWc804sEp2rit-OldKaSsz_mih7r1wAu8z25zCK6T3Zvj-Eztx8SJiMaGv8ZsIXzbIJrv7mxv17_3aKNA</span><br></pre></td></tr></table></figure><p>将token值输入到令牌后，单击登录即可访问Dashboard<br><img src="file://D:/Resource/xukun_blog/source/_posts/2021/12/Kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/image-20211205133743076.png?lastModify=1638682375" alt="image-20211205133743076"></p><p>一些必须的配置更改</p><p>将Kube-proxy改为ipvs模式，因为在初始化集群的时候注释了ipvs配置，所以需要自行修改一下：</p><p>在master01节点执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit cm kube-proxy -n kube-system</span><br></pre></td></tr></table></figure><p>修改为 ipvs</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mode:</span> <span class="string">“ipvs”</span></span><br></pre></td></tr></table></figure><p>更新 Kube-Proxy 的 Pod：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch daemonset kube-proxy -p &quot;&#123;\&quot;spec\&quot;:&#123;\&quot;template\&quot;:&#123;\&quot;metadata\&quot;:&#123;\&quot;annotations\&quot;:&#123;\&quot;date\&quot;:\&quot;`date +&#x27;%s&#x27;`\&quot;&#125;&#125;&#125;&#125;&#125;&quot; -n kube-system</span><br></pre></td></tr></table></figure><p>在 master03 验证 Kube-Proxy 模式，接着可以在所有服务器验证一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl 127.0.0.1:10249/proxyMode</span><br></pre></td></tr></table></figure><p>注意事项<br>kubeadm安装的集群，证书有效期默认是一年。master节点的kube-apiserver、kube-scheduler、kube-controller-manager、etcd都是以容器运行的。可以通过kubectl get po -n kube-system查看。</p><p>启动和二进制的区别：<br>kubelet的配置文件在/etc/sysconfig/kubelet和/var/lib/kubelet/config.yaml，修改后需要重启kubelet进程</p><p>其他组件的配置文件在/etc/kubernetes/manifests目录下，比如kube-apiserver.yaml，该yaml文件更改后，kubelet会自动刷新配置，也就是会重启pod。不能再次创建该文件</p><p>kube-proxy的配置在kube-system命名空间下的configmap中，可以通过</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit cm kube-proxy -n kube-system</span><br></pre></td></tr></table></figure><p>Kubeadm安装后，master节点默认不允许部署pod，会占用资源，在学习过程中可以通过以下方式打开：</p><p>查看Taints：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl  describe node -l node-role.kubernetes.io/master=  | grep Taints</span><br></pre></td></tr></table></figure><p>可以看到三个污点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br></pre></td></tr></table></figure><p>删除Taint：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl  taint node  -l node-role.kubernetes.io/master node-role.kubernetes.io/master:NoSchedule-</span><br></pre></td></tr></table></figure><p>再次查看：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl  describe node -l node-role.kubernetes.io/master=  | grep Taints</span><br><span class="line">Taints:             &lt;none&gt;</span><br><span class="line">Taints:             &lt;none&gt;</span><br><span class="line">Taints:             &lt;none&gt;</span><br></pre></td></tr></table></figure><h2 id="13-集群验证"><a href="#13-集群验证" class="headerlink" title="13.集群验证"></a>13.集群验证</h2><p>查看kubernetes服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line"></span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   63m</span><br><span class="line"></span><br><span class="line">kubectl get svc -n kube-system</span><br><span class="line"></span><br><span class="line">NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">kube-dns         ClusterIP   10.96.0.10      &lt;none&gt;        53/UDP,53/TCP,9153/TCP   63m</span><br><span class="line">metrics-server   ClusterIP   10.101.237.26   &lt;none&gt;        443/TCP                  22m</span><br></pre></td></tr></table></figure><p><strong>所有节点</strong>可以连接kubernetes和kube-dns服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br></pre></td></tr></table></figure><p><strong>所有节点</strong>可以ping通pod的ip地址</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">kubectl get po --all-namespaces -owide</span><br><span class="line">NAMESPACE              NAME                                         READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system            calico-kube-controllers-cdd5755b9-78fsd      1/1     Running   0             41m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            calico-node-8m2wm                            1/1     Running   0             41m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            calico-node-9cb4j                            1/1     Running   0             41m   192.168.1.203    k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            calico-node-bljgv                            1/1     Running   0             41m   192.168.1.204    k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            calico-node-chqv8                            1/1     Running   0             41m   192.168.1.202    k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            calico-node-t97kd                            1/1     Running   0             41m   192.168.1.205    k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            coredns-7d89d9b6b8-7zvlw                     1/1     Running   0             65m   172.168.32.129   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            coredns-7d89d9b6b8-zmth2                     1/1     Running   0             65m   172.168.32.130   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            etcd-k8s-master01                            1/1     Running   0             65m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            etcd-k8s-master02                            1/1     Running   0             63m   192.168.1.202    k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            etcd-k8s-master03                            1/1     Running   0             62m   192.168.1.203    k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-apiserver-k8s-master01                  1/1     Running   0             65m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-apiserver-k8s-master02                  1/1     Running   0             63m   192.168.1.202    k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-apiserver-k8s-master03                  1/1     Running   0             62m   192.168.1.203    k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-controller-manager-k8s-master01         1/1     Running   1 (63m ago)   65m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-controller-manager-k8s-master02         1/1     Running   0             63m   192.168.1.202    k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-controller-manager-k8s-master03         1/1     Running   0             62m   192.168.1.203    k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-proxy-fln4s                             1/1     Running   0             63m   192.168.1.202    k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-proxy-fnbns                             1/1     Running   0             65m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-proxy-hngtq                             1/1     Running   0             62m   192.168.1.203    k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-proxy-prk44                             1/1     Running   1             54m   192.168.1.204    k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-proxy-tn8bt                             1/1     Running   1             54m   192.168.1.205    k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-scheduler-k8s-master01                  1/1     Running   1 (63m ago)   65m   192.168.1.201    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-scheduler-k8s-master02                  1/1     Running   0             63m   192.168.1.202    k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            kube-scheduler-k8s-master03                  1/1     Running   0             62m   192.168.1.203    k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            metrics-server-d6c46b546-5db6j               1/1     Running   0             24m   172.168.58.193   k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kubernetes-dashboard   dashboard-metrics-scraper-86bb69c5f6-ngsvt   1/1     Running   0             23m   172.168.58.194   k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kubernetes-dashboard   kubernetes-dashboard-6576c84894-tmpx9        1/1     Running   0             23m   172.168.85.193   k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">ping 172.168.58.193 -c 4</span><br><span class="line">PING 172.168.58.193 (172.168.58.193) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.168.58.193: icmp_seq=1 ttl=63 time=0.456 ms</span><br><span class="line">64 bytes from 172.168.58.193: icmp_seq=2 ttl=63 time=0.356 ms</span><br><span class="line">64 bytes from 172.168.58.193: icmp_seq=3 ttl=63 time=0.337 ms</span><br><span class="line">64 bytes from 172.168.58.193: icmp_seq=4 ttl=63 time=0.552 ms</span><br></pre></td></tr></table></figure><p>非当前机器的pod之间的ip互通</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec -it calico-node-bljgv -n kube-system -- sh</span><br><span class="line"></span><br><span class="line">ping 172.168.32.130 -c 4</span><br></pre></td></tr></table></figure><p>NodePort局域网内可以正常访问</p></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Kubernetes/">Kubernetes</a></div></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021-12-05/bea16a9fbd52/"><span class="level-item">二进制安装kubernetes集群</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({el:"#valine-thread",appId:"65tFyGDn4EMiUfSEMfvTLUP6-gzGzoHsz",appKey:"QPrgz16XHEeBNRxyPMla4RBP",placeholder:"请自觉遵守互联网相关的政策法规，严禁发布色情、暴力、反动的言论。",avatar:"mm",avatarForce:!1,meta:["nick","mail"],pageSize:10,lang:"zh-CN",visitor:!1,highlight:!0,recordIP:!1,enableQQ:!1,requiredFields:[]})</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="蔚蓝海"></figure><p class="title is-size-4 is-block" style="line-height:inherit">蔚蓝海</p><p class="is-size-6 is-block">JAVA程序猿</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">9</p></a></div></div></nav></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#1-安装说明"><span class="level-left"><span class="level-item">1</span><span class="level-item">1. 安装说明</span></span></a></li><li><a class="level is-mobile" href="#2-节点规划"><span class="level-left"><span class="level-item">2</span><span class="level-item">2. 节点规划</span></span></a></li><li><a class="level is-mobile" href="#3-基本配置"><span class="level-left"><span class="level-item">3</span><span class="level-item">3. 基本配置</span></span></a></li><li><a class="level is-mobile" href="#4-内核配置"><span class="level-left"><span class="level-item">4</span><span class="level-item">4. 内核配置</span></span></a></li><li><a class="level is-mobile" href="#5-基本组件安装"><span class="level-left"><span class="level-item">5</span><span class="level-item">5. 基本组件安装</span></span></a></li><li><a class="level is-mobile" href="#6-高可用组件安装"><span class="level-left"><span class="level-item">6</span><span class="level-item">6. 高可用组件安装</span></span></a></li><li><a class="level is-mobile" href="#7-集群初始化"><span class="level-left"><span class="level-item">7</span><span class="level-item">7. 集群初始化</span></span></a></li><li><a class="level is-mobile" href="#8-高可用Master"><span class="level-left"><span class="level-item">8</span><span class="level-item">8. 高可用Master</span></span></a></li><li><a class="level is-mobile" href="#9-添加Node节点"><span class="level-left"><span class="level-item">9</span><span class="level-item">9. 添加Node节点</span></span></a></li><li><a class="level is-mobile" href="#10-Calico安装"><span class="level-left"><span class="level-item">10</span><span class="level-item">10. Calico安装</span></span></a></li><li><a class="level is-mobile" href="#11-Metrics-Server部署"><span class="level-left"><span class="level-item">11</span><span class="level-item">11. Metrics Server部署</span></span></a></li><li><a class="level is-mobile" href="#12-Dashboard部署"><span class="level-left"><span class="level-item">12</span><span class="level-item">12. Dashboard部署</span></span></a></li><li><a class="level is-mobile" href="#13-集群验证"><span class="level-left"><span class="level-item">13</span><span class="level-item">13.集群验证</span></span></a></li></ul></div></div><style>#toc .menu-list>li>a.is-active+.menu-list{display:block}#toc .menu-list>li>a+.menu-list{display:none}</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">学习笔记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BA%91%E5%8E%9F%E7%94%9F/"><span class="level-start"><span class="level-item">云原生</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/"><span class="level-start"><span class="level-item">工具安装</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/%E5%89%8D%E7%AB%AF/"><span class="level-start"><span class="level-item">前端</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/%E5%90%8E%E7%AB%AF/"><span class="level-start"><span class="level-item">后端</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%97%A5%E5%B8%B8%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">日常随笔</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%97%A5%E5%B8%B8%E9%9A%8F%E7%AC%94/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"><span class="level-start"><span class="level-item">问题记录</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2021-12-05T05:57:46.000Z">2021-12-05</time></p><p class="title"><a href="/2021-12-05/88b8770560e1/">kubeadm安装kubernetes集群</a></p><p class="categories"><a href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/">工具安装</a> / <a href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/%E5%90%8E%E7%AB%AF/">后端</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-12-05T05:57:19.000Z">2021-12-05</time></p><p class="title"><a href="/2021-12-05/bea16a9fbd52/">二进制安装kubernetes集群</a></p><p class="categories"><a href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/">工具安装</a> / <a href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/%E5%90%8E%E7%AB%AF/">后端</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-11-21T08:19:06.000Z">2021-11-21</time></p><p class="title"><a href="/2021-11-21/4ada93cc441a/">Docker入门</a></p><p class="categories"><a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> / <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BA%91%E5%8E%9F%E7%94%9F/">云原生</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-11-21T08:14:46.000Z">2021-11-21</time></p><p class="title"><a href="/2021-11-21/f01fc1ab108a/">MariaDB、JDK及Redis安装指南</a></p><p class="categories"><a href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/">工具安装</a> / <a href="/categories/%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/%E5%90%8E%E7%AB%AF/">后端</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-11-21T08:10:38.000Z">2021-11-21</time></p><p class="title"><a href="/2021-11-21/e66b8f2cdbc7/">Shiro修改角色权限没有生效</a></p><p class="categories"><a href="/categories/%E6%97%A5%E5%B8%B8%E9%9A%8F%E7%AC%94/">日常随笔</a> / <a href="/categories/%E6%97%A5%E5%B8%B8%E9%9A%8F%E7%AC%94/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/">问题记录</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">十二月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">十一月 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JDK/"><span class="tag">JDK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kubernetes/"><span class="tag">Kubernetes</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MariaDB/"><span class="tag">MariaDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MyBatis-Plus/"><span class="tag">MyBatis-Plus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shiro/"><span class="tag">Shiro</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">XuKun&#039;s Blog</a><p class="is-size-7"><span>&copy; 2021 蔚蓝海</span>  Powered by <a rel="noopener" href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a rel="noopener" href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load",()=>{"function"==typeof $.fn.lightGallery&&$(".article").lightGallery({selector:".gallery-item"}),"function"==typeof $.fn.justifiedGallery&&($(".justified-gallery > p > .gallery-item").length&&$(".justified-gallery > p > .gallery-item").unwrap(),$(".justified-gallery").justifiedGallery())})</script><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"想要查找什么...",untitled:"(无标题)",posts:"文章",pages:"页面",categories:"分类",tags:"标签"})})</script></body></html>